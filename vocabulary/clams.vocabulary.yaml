# Changes in this file will automatically increase versions of changed object.
# The versions of types included in a particular MMIF (more specifically CLAMS vocab)
# is recorded under `docs/x.y.z/vocabulary/ATTYPE_VERSIONS_JSONFILENAME`
# Note that individuated type versioning is introduced after 0.4.2, 
# so `docs/x.y.z` sub-directories of <= 0.4.2 won't have that JSON files.

name: Thing
parent: null

description: >-
  Abstract top type.

properties:
  id:
    type: ID
    description: >-
      A unique identifier for the annotation or document. Uniqueness is relative to the view
      the annotation is in or the list of documents at the top level of a MMIF file.
    required: true

---

name: Annotation
parent: Thing

description: >-
  Any kind of information added to a document. 
  If an annotation is specific to a region over the primary data or a relation over such regions, 
  specific sub-types should be used instead of this high-level type. 


metadata:
  document:
    type: ID
    description: >-
      The identifier of the document that the annotation is over. This has to be
      defined either at the metadata level, in which case it has scope over all
      annotations of the same type in a view, or at the instance level, in which
      it has scope over just the single annotation.
  labelset:
    type: List of Strings
    description: >-
      When an annotation object contains results of a classification task,
      this metadata is used to specify the label values used in classification.
      Individual annotations then must have <code>label</code> property that
      is one of the values in this list. 
      <br><br>
      [Note] Annotations from a classifier app must have this metadata or <code>
      labelsetUri </code> metadata.
      <br><br>
      [Note] Not all of labels specified
      in the <code>labelset</code> must occur in the output annotations. For 
      example, a <code>labelset</code> can contain a <i>catch-all</i> negative
      label, but if the negative label can be not interesting enough to keep in 
      the output annotation.
  labelsetUri:
    type: String
    description: >-
      A URI to an externally defined labelset. Since the <code>labelset</code>
      metadata is a list of simple strings, this URI can be used to point to a
      more detailed definition of the labelset. This can be a JSON-LD document
      or a SKOS concept scheme, for example. 
      <br><br>
      [Note] Annotations from a classifier app must have this metadata or <code>
      labelset </code> metadata.

properties:
  document:
    type: ID
    description: >-
      The identifier of the document that the annotation is over.
  label:
    type: String
    description: >-
      A label given to this object by a classifier. The value must be a simple 
      string value of the label and must be one of the values defined in the
      <code>labelset</code> or <code>labelsetUri</code> annotation metadata.
      <br><br>
      [Note] Annotations from a classifier app must have this property.
  classifications:
    type: Map from String to Number
    description: >-
      Alias for the <code>classification</code> metadata. Here for historical
      reasons.
  classification:
    type: Map from String to Number
    description: >-
      A map from label values to their "score" numbers provided by a classifier.
      The score can be probability, similarity, confidence, or any other real 
      number that was used to determine the label value. 
      <br><br>
      [Optional] on top of the <code>label</code> property. However when this 
      property is used, the <code>label</code> property must be one of the keys
      and the keys must match to the values defined in the <code>labelset</code>
        or <code>labelsetUri</code> annotation metadata.

---

name: Region
parent: Annotation

description: >-
  An annotation over a region in primary data where primary data can be a text,
  an image, an audio stream or a video streem. Typically one of the sub types
  of this will be used.

metadata:
  timeUnit:
    type: String
    description: >-
      Specifies which unit of time the measurement is based. 
      Can be *seconds* or *milliseconds*, or in case of annotations on 
      a VideoDocument, *frames*. 

---

name: TimePoint
parent: Region

description: >-
  A time point in an audio or video stream.

properties:
  timePoint:
    type: Integer
    description: The starting offset in the stream.
    required: true

---

name: Interval
parent: Region

description: >-
  An annotation over an interval of linear primary data, either a text, a video 
  or audio stream. An Interval may be defined by pointing directly into 
  primary data (by using start and end offsets) or by linking to one or
  more other Annotations with the targets property. This annotation type is
  intended to be an abstract type and typically one of the sub types will be
  used.

properties:
  start:
    type: Integer
    description: >-
      The starting offset in the primary data. This point is inclusive. 
      For time intervals, the unit is determined by the *timeUnit* metadata key.
      For text intervals, the unit is Unicode code point. 
  end:
    type: Integer
    description: >-
      The ending offset in the primary data. This point is exclusive. 
      For time intervals, the unit is determined by the *timeUnit* metadata key.
      For text intervals, the unit is Unicode code point. 
  targets:
    type: List of IDs
    description: >-
      IDs of a sequence of annotations covering the region of primary data
      referred to by this annotation. Used as an alternative to *start* and
      *end* to point to component annotations (for example a token sequence)
      rather than directly into primary data, or to link two or more annotations
      (for example in a coreference annotation).

---

name: Span
parent: Interval

similarTo:
  - http://vocab.lappsgrid.org/Region

description: >-
  An annotation over a region in primary text data. A Span may be defined by
  pointing directly into primary data (by using start and end offsets) or
  by linking to one or more other Annotations with the targets property.

---

name: Token
parent: Span

similarTo:
  - http://vocab.lappsgrid.org/Token

description: >-
  A string of one or more characters that serves as an indivisible unit 
  for the purposes of morpho-syntactic labeling (part of speech tagging).

properties:
  pos:
    type: String or URI
    description: Part-of-speech tag associated with the token.
  lemma:
    type: String or URI
    description: >-
      The root (base) form associated with the token. URI may point to a 
      lexicon entry.
  tokenType:
    type: String or URI
    description: >-
      Sub-type such as word, punctuation, abbreviation, number, symbol, etc. 
      Ideally a URI referencing a pre-defined descriptor.
  orth:
    type: String or URI
    description: >-
      Orthographic properties of the token such as LowerCase, UpperCase, 
      UpperInitial, etc. Ideally a URI referencing a pre-defined descriptor.
  word:
    type: String
    description: The surface string in the primary data covered by this Token.

---

name: Sentence
parent: Span

similarTo:
  - http://vocab.lappsgrid.org/Sentence

description: >
  A sequence of words capable of standing alone to make an assertion, ask a
  question, or give a command, usually consisting of a subject and a predicate
  containing a finite verb.

properties:
  sentenceType:
    type: String or URI
    description: >-
      Values such as declarative, interrogative, exclamatory, question,
      fragment. Ideally a URI referencing a pre-defined descriptor.

---

name: Paragraph
parent: Span

similarTo:
  - http://vocab.lappsgrid.org/Paragraph

description: >-
  A division of a piece of writing, usually dealing with a single theme and 
  indicated by a new line, indentation, and/or numbering.

---

name: NamedEntity
parent: Span

similarTo:
  - http://vocab.lappsgrid.org/NamedEntity

description: >-
  A phrase that clearly identifies an individual from others that have similar 
  attributes, such as the name of a person, organization, location, artifact, 
  etc. as well as temporal expressions.

metadata:
  namedEntityCategorySet:
    type: String or URI
    description: The set of values that can be used for the category property.

properties:
  category:
    type: String or URI
    required: true
    description: >-
      The type of named entity. Typically one of DATE, PERSON, ORGANIZATION,
      or LOCATION.
  type:
    type: String or URI
    description: >-
      A type attribute for the entity. For example the type of location or
      organization.
  gender:
    type: String or URI
    description: >-
      A value such as male, female, unknown. Ideally a URI referencing a
      pre-defined descriptor.

---

name: NounChunk
parent: Span

similarTo:
  - http://vocab.lappsgrid.org/NounChunk

description: >-
  The initial portion of a non-recursive noun phrase up to the head, including 
  determiners but not including postmodifying prepositional phrases or clauses.

---

name: VerbChunk
parent: Span

similarTo: 
  - http://vocab.lappsgrid.org/VerbChunk
  
description: >-
  Non-recursive verb groups, which include modals, auxiliary verbs, and medial
  adverbs, and end at the head verb or predicate adjective.

properties:
  vcType:
    type: String or URI
    description: >-
      Values such as finite, non-finite, participle, modal, special (e.g., 'is
      going to investigate').
  tense:
    type: String or URI
    description: >-
      Provides tense information for the verb. Example values include BeVBG,
      BeVBN, FutCon, HaveVBN, Pas, PasCon, PasPer, PasPerCon, Per, Pre, PreCon,
      PrePer, PrePerCon, SimFut, SimPas, SimPre, none
  voice:
    type: String or URI
    description: >-
      Indicates if the verb group is active or passive. Possible values include
      ACTIVE, PASSIVE, or NONE
  neg:
    type: String or URI
    description: Indicates whether or not the verb is negated. Values include YES, NO.

---

name: TimeFrame
parent: Interval

description: >-
  A temporal interval in an audio or video stream. This is similar to the term
  segment used in audio processing, but that term has a different meaning in the
  image and video community.


properties:
  frameType:
    type: String
    description: The type of TimeFrame. Possible values include, but are not
      limited to, bars, tones, bars-and-tones, speech, noise, music, slate,
      chyron, lower-third, credits, and other.
      <br><br>
      No longer encouraged to use, instead <code>label</code> property
      should replace this property.


---

name: Chapter
parent: TimeFrame
description: >-
  Example case for when we do not want to use Segment with a specific
  segmentType or if we want to introduce special properties.

properties:
  title:
    type: String
    description: Title of the chapter

---

name: Polygon
parent: Region

description: >-
  A polygon in an image or video. This is a two-dimensional object so if this
  occurs in a video it will be anchored to a particular frame or time point in
  the video.

properties:
  coordinates:
    type: List of pairs
    description: The coordinates of the polygon, taking the top-left of the image
      as the origin (0,0). Unit used to measure the distance is the number of pixels.
    required: true
  timePoint:
    type: Integer
    description: If on a video stream, the TimePoint that the BoundingBox occurs in.

---

name: BoundingBox
parent: Polygon

description: >-
  A rectangular object in an image or video. At the moment it does not have
  features that would not make any sense on its parent type Polygon so
  technically we can do without BoundingBox, but it was introduced because the
  term is in widespread use.

properties:
  boxType:
    type: String
    description: >-
      The type of BoundingBox. Mostly used for text boxes where we use the value text.
      <br><br>
      No longer encouraged to use, and instead <code>label</code> property 
      should replace this property.

---

name: VideoObject
parent: Region

description: >-
  A sequence of Polygons, where each Polygon is associated with a
  TimePoint. So a VideoObject is in effect a sequence of image objects at
  certain time points.

properties:
  polygons:
    type: List of IDs
    description: The Polygons that make up the object.
    required: true

---

name: Relation
parent: Annotation

description: >-
  Any relationship between two or more annotation types. For texts could be a
  grammatical relation such as subject-object, a semantic relation between
  meanings or roles, or a temporal relation indicating the simultaneity or
  ordering in time of events or states. For image regions and video objects this
  could involve spatial relations or part-whole relations.

---

name: Document
parent: Thing

description: >-
  A document of some media type. Annotations directly or indirectly anchor to
  documents. In CLAMS, a document typically refers to an external file fia the
  *location* property, but for text documents the actual content can be in-line
  in the document type.

properties:
  location:
    type: String
    description: The location of an external file.
  mime:
    type: String or URI
    description: The MIME type of the document, only used when the *location* property is used.

---

name: VideoDocument
parent: Document

description: >-
  A video document.

---

name: AudioDocument
parent: Document

description: >-
  An audio document.

---

name: ImageDocument
parent: Document

description: >-
  An image document.

---

name: TextDocument
parent: Document

description: >-
  A text document.

properties:
  text:
    type: Object
    description: >-
      A JSON-LD value object which has a *@value* and a *@language* property.

---

name: Alignment
parent: Thing

description: >-
  An alignment between two regions, two documents or a region and a
  document. Typically one of the regions or documents is a text span or text
  document and the other an image or audio segment or document. While there is no
  enforced directionality we tend to consider the text region or document as the
  target of the alignment.

metadata:
  sourceType:
    type: URI
    description: >-
      The type of sources of the alignment. When an alignment starts from more that two source types, namely sources can be different types, one should not use this metadata.

  targetType:
    type: URI
    description: >-
      The type of targets of the alignment. When an alignment goes to more that two target types, namely targets can be different types, one should not use this metadata.

properties:
  source:
    type: ID
    description: The first of the aligned regions or documents.
    required: true
  target:
    type: ID
    description: The second of the aligned regions or documents.
    required: true
